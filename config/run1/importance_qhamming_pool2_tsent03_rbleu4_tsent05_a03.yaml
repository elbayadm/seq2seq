modelname : importance_qhamming_pool2_tsent03_rbleu4_tsent05_a03
model: attention

# Data:
input_data_src: data/WMT14/en_src_cmp
input_data_trg: data/WMT14/fr_trg_cmp

# batch_size: 10
# valid_batch_size: 25
max_epochs : 5
# loss:
loss_version : seq
stratify_reward : 0
alpha_sent : 0.3

reward : bleu4
tau_sent : 0.5

importance_sampler : hamming
tau_sent_q : 0.3
limited_vocab_sub : 2


