modelname : strat_rhamming_pool1_tsent01_a03_wmt14_full_lr3
model: attention

# Data:
input_data_src: data/WMT14_FULL/en_src
input_data_trg: data/WMT14_FULL/fr_trg

batch_size: 32
valid_batch_size: 10
decode: greedy 
model: attention
max_epochs : 4
learning_rate : 5e-4

# encoder
num_layers_src : 3
rnn_size_src : 1024
max_src_length : 80

# decoder
num_layers_src : 3
rnn_size_trg : 1024
max_trg_length : 80

# Loss:
loss_version : seq
reward : hamming
stratify_reward  : 1
tau_sent : .1
alpha_sent : 0.3
